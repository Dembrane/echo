# Core API metadata
BUILD_VERSION=dev
API_BASE_URL=http://localhost:8000
ADMIN_BASE_URL=http://localhost:5173
PARTICIPANT_BASE_URL=http://localhost:5174

# Directus / authentication
DIRECTUS_BASE_URL=http://directus:8055
DIRECTUS_SECRET=<directus_app_secret>
DIRECTUS_TOKEN=<directus_static_token>
DIRECTUS_SESSION_COOKIE_NAME=directus_session_token

# Persistence / cache
DATABASE_URL=postgresql+psycopg://dembrane:dembrane@postgres:5432/dembrane
REDIS_URL=redis://redis:6379

# Object storage
STORAGE_S3_BUCKET=dembrane-audio
STORAGE_S3_REGION=us-east-1
STORAGE_S3_ENDPOINT=https://s3.amazonaws.com
STORAGE_S3_KEY=<aws_access_key_id>
STORAGE_S3_SECRET=<aws_secret_access_key>

############################################################
# Feature toggles
############################################################
DEBUG_MODE=0
DISABLE_CORS=0
DISABLE_REDACTION=0
DISABLE_CHAT_TITLE_GENERATION=0
ENABLE_CHAT_AUTO_SELECT=0
SERVE_API_DOCS=0
DISABLE_SENTRY=0

############################################################
# Transcription providers
############################################################
TRANSCRIPTION_PROVIDER=
ASSEMBLYAI_API_KEY=
ASSEMBLYAI_BASE_URL=https://api.eu.assemblyai.com

# LiteLLM transcription (used when TRANSCRIPTION_PROVIDER=LiteLLM)
LITELLM_TRANSCRIPTION_MODEL=whisper-1
LITELLM_TRANSCRIPTION_API_KEY=<openai_api_key>
LITELLM_TRANSCRIPTION_API_BASE=https://api.openai.com/v1
LITELLM_TRANSCRIPTION_API_VERSION=2024-02-01
# Raw JSON or base64-encoded service account (set when TRANSCRIPTION_PROVIDER requires GCP)
GCP_SA_JSON=

############################################################
# LLM configuration (three model groups)
############################################################

# Multi-modal Pro – high-context reasoning (Gemini Pro on Vertex)
LLM__MULTI_MODAL_PRO__MODEL=vertex_ai/gemini-2.5-pro
LLM__MULTI_MODAL_PRO__API_BASE=https://europe-west1-aiplatform.googleapis.com
LLM__MULTI_MODAL_PRO__API_VERSION=
LLM__MULTI_MODAL_PRO__GCP_SA_JSON=${GCP_SA_JSON}
LLM__MULTI_MODAL_PRO__VERTEX_PROJECT=<vertex_project_id>
LLM__MULTI_MODAL_PRO__VERTEX_LOCATION=europe-west1

# Multi-modal Fast – Gemini Flash (Vertex)
LLM__MULTI_MODAL_FAST__MODEL=vertex_ai/gemini-2.5-flash
LLM__MULTI_MODAL_FAST__API_BASE=https://europe-west1-aiplatform.googleapis.com
LLM__MULTI_MODAL_FAST__API_VERSION=
LLM__MULTI_MODAL_FAST__GCP_SA_JSON=${GCP_SA_JSON}
LLM__MULTI_MODAL_FAST__VERTEX_PROJECT=<vertex_project_id>
LLM__MULTI_MODAL_FAST__VERTEX_LOCATION=europe-west1

# Text Fast – Claude Sonnet on Vertex
LLM__TEXT_FAST__MODEL=vertex_ai/claude-3-5-sonnet-20241022
LLM__TEXT_FAST__API_BASE=https://europe-west1-aiplatform.googleapis.com
LLM__TEXT_FAST__API_VERSION=
LLM__TEXT_FAST__GCP_SA_JSON=${GCP_SA_JSON}
LLM__TEXT_FAST__VERTEX_PROJECT=<vertex_project_id>
LLM__TEXT_FAST__VERTEX_LOCATION=europe-west1

############################################################
# Embedding configuration
############################################################
EMBEDDING_MODEL=vertex_ai/text-embedding-004
EMBEDDING_API_KEY=
EMBEDDING_BASE_URL=https://europe-west1-aiplatform.googleapis.com
EMBEDDING_API_VERSION=
